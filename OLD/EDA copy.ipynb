{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from textstat import textstat\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Inspecting the Dataset\n",
    "Load the cleaned dataset and inspect its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 742 entries, 0 to 741\n",
      "Data columns (total 50 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Unnamed: 0                  742 non-null    int64  \n",
      " 1   Job Title                   742 non-null    object \n",
      " 2   Salary Estimate             742 non-null    object \n",
      " 3   Job Description             742 non-null    object \n",
      " 4   Rating                      742 non-null    float64\n",
      " 5   Company Name                742 non-null    object \n",
      " 6   Location                    742 non-null    object \n",
      " 7   Headquarters                742 non-null    object \n",
      " 8   Size                        742 non-null    object \n",
      " 9   Founded                     742 non-null    int64  \n",
      " 10  Type of ownership           742 non-null    object \n",
      " 11  Industry                    742 non-null    object \n",
      " 12  Sector                      742 non-null    object \n",
      " 13  Revenue                     742 non-null    object \n",
      " 14  Competitors                 742 non-null    object \n",
      " 15  hourly                      742 non-null    int64  \n",
      " 16  employer_provided           742 non-null    int64  \n",
      " 17  min_salary                  742 non-null    int64  \n",
      " 18  max_salary                  742 non-null    int64  \n",
      " 19  avg_salary                  742 non-null    float64\n",
      " 20  company_txt                 742 non-null    object \n",
      " 21  job_state                   742 non-null    object \n",
      " 22  same_state                  742 non-null    int64  \n",
      " 23  age                         742 non-null    int64  \n",
      " 24  python_yn                   742 non-null    int64  \n",
      " 25  R_yn                        742 non-null    int64  \n",
      " 26  spark                       742 non-null    int64  \n",
      " 27  aws                         742 non-null    int64  \n",
      " 28  excel                       742 non-null    int64  \n",
      " 29  job_simp                    742 non-null    object \n",
      " 30  seniority                   742 non-null    object \n",
      " 31  desc_len                    742 non-null    int64  \n",
      " 32  num_comp                    742 non-null    int64  \n",
      " 33  headquarters_state          742 non-null    object \n",
      " 34  Lemmatized_Description      742 non-null    object \n",
      " 35  Agentic_Words               742 non-null    object \n",
      " 36  Communal_Words              734 non-null    object \n",
      " 37  Agentic_Count               742 non-null    int64  \n",
      " 38  Communal_Count              742 non-null    int64  \n",
      " 39  Gendered_Ratio              742 non-null    float64\n",
      " 40  job_state_encoded           742 non-null    int64  \n",
      " 41  headquarters_state_encoded  742 non-null    int64  \n",
      " 42  Type of ownership_encoded   742 non-null    int64  \n",
      " 43  Industry_encoded            742 non-null    int64  \n",
      " 44  Sector_encoded              742 non-null    int64  \n",
      " 45  job_simp_encoded            742 non-null    int64  \n",
      " 46  seniority_encoded           742 non-null    int64  \n",
      " 47  num_comp_encoded            742 non-null    int64  \n",
      " 48  Ratio                       742 non-null    float64\n",
      " 49  Gender_Bias                 742 non-null    int64  \n",
      "dtypes: float64(4), int64(26), object(20)\n",
      "memory usage: 290.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('gendered_data.csv')\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Communal_Words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(word \u001b[39min\u001b[39;00m description \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m word_list)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Calculate communal and agentic scores\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcommunal_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: word_count(x, Communal_Words))\n\u001b[1;32m     10\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39magentic_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: word_count(x, Agentic_Words))\n\u001b[1;32m     12\u001b[0m \u001b[39m# Calculate frequency of communal and agentic words\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[39m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[39m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[39m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[39m=\u001b[39mcurried, na_action\u001b[39m=\u001b[39maction, convert\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39mna_action, convert\u001b[39m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(values, mapper, convert\u001b[39m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(word \u001b[39min\u001b[39;00m description \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m word_list)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Calculate communal and agentic scores\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcommunal_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: word_count(x, Communal_Words))\n\u001b[1;32m     10\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39magentic_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: word_count(x, Agentic_Words))\n\u001b[1;32m     12\u001b[0m \u001b[39m# Calculate frequency of communal and agentic words\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Communal_Words' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the function for word count\n",
    "def word_count(description, word_list):\n",
    "    \"\"\"\n",
    "    Count the occurrences of words in the given word_list within the description.\n",
    "    \"\"\"\n",
    "    return sum(word in description for word in word_list)\n",
    "\n",
    "# Calculate communal and agentic scores\n",
    "df['communal_score'] = df['Lemmatized_Description'].apply(lambda x: word_count(x, Communal_Words))\n",
    "df['agentic_score'] = df['Lemmatized_Description'].apply(lambda x: word_count(x, Agentic_Words))\n",
    "\n",
    "# Calculate frequency of communal and agentic words\n",
    "df['communal_freq'] = df['communal_score'] / df['Lemmatized_Description'].apply(len)\n",
    "df['agentic_freq'] = df['agentic_score'] / df['Lemmatized_Description'].apply(len)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['communal_score'].plot(kind='hist', alpha=0.5, label='Communal Score', color='blue')\n",
    "df['agentic_score'].plot(kind='hist', alpha=0.5, label='Agentic Score', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.title('Distribution of Communal and Agentic Scores in Job Descriptions')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['communal_freq'].plot(kind='hist', alpha=0.5, label='Communal Frequency', color='blue')\n",
    "df['agentic_freq'].plot(kind='hist', alpha=0.5, label='Agentic Frequency', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Frequency')\n",
    "plt.title('Distribution of Communal and Agentic Frequencies in Job Descriptions')\n",
    "plt.show()\n",
    "\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'desc_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Calculate communal and agentic scores\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcommunal_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: desc_len(x, Communal_Words))\n\u001b[1;32m      3\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39magentic_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: desc_len(x, Agentic_Words))\n\u001b[1;32m      5\u001b[0m \u001b[39m# Calculate frequency of communal and agentic words\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[39m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[39m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[39m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[39m=\u001b[39mcurried, na_action\u001b[39m=\u001b[39maction, convert\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39mna_action, convert\u001b[39m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(values, mapper, convert\u001b[39m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Calculate communal and agentic scores\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcommunal_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: desc_len(x, Communal_Words))\n\u001b[1;32m      3\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39magentic_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: desc_len(x, Agentic_Words))\n\u001b[1;32m      5\u001b[0m \u001b[39m# Calculate frequency of communal and agentic words\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'desc_len' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate communal and agentic scores\n",
    "df['communal_score'] = df['Lemmatized_Description'].apply(lambda x: desc_len(x, Communal_Words))\n",
    "df['agentic_score'] = df['Lemmatized_Description'].apply(lambda x: desc_len(x, Agentic_Words))\n",
    "\n",
    "# Calculate frequency of communal and agentic words\n",
    "df['communal_freq'] = df['communal_score'] / df['Lemmatized_Description'].apply(len)\n",
    "df['agentic_freq'] = df['agentic_score'] / df['Lemmatized_Description'].apply(len)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['communal_score'].plot(kind='hist', alpha=0.5, label='Communal Score', color='blue')\n",
    "df['agentic_score'].plot(kind='hist', alpha=0.5, label='Agentic Score', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.title('Distribution of Communal and Agentic Scores in Job Descriptions')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['communal_freq'].plot(kind='hist', alpha=0.5, label='Communal Frequency', color='blue')\n",
    "df['agentic_freq'].plot(kind='hist', alpha=0.5, label='Agentic Frequency', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Frequency')\n",
    "plt.title('Distribution of Communal and Agentic Frequencies in Job Descriptions')\n",
    "plt.show()\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Calculate communal and agentic scores\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcommunal_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: count_words(x, Communal_Words))\n\u001b[1;32m      3\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39magentic_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: count_words(x, Agentic_Words))\n\u001b[1;32m      5\u001b[0m \u001b[39m# Calculate frequency of communal and agentic words\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[39m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[39m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[39m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[39m=\u001b[39mcurried, na_action\u001b[39m=\u001b[39maction, convert\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39mna_action, convert\u001b[39m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer(values, mapper, convert\u001b[39m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Calculate communal and agentic scores\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcommunal_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: count_words(x, Communal_Words))\n\u001b[1;32m      3\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39magentic_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLemmatized_Description\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: count_words(x, Agentic_Words))\n\u001b[1;32m      5\u001b[0m \u001b[39m# Calculate frequency of communal and agentic words\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count_words' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate communal and agentic scores\n",
    "df['communal_score'] = df['Lemmatized_Description'].apply(lambda x: count_words(x, Communal_Words))\n",
    "df['agentic_score'] = df['Lemmatized_Description'].apply(lambda x: count_words(x, Agentic_Words))\n",
    "\n",
    "# Calculate frequency of communal and agentic words\n",
    "df['communal_freq'] = df['communal_score'] / df['Lemmatized_Description'].apply(len)\n",
    "df['agentic_freq'] = df['agentic_score'] / df['Lemmatized_Description'].apply(len)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['communal_score'].plot(kind='hist', alpha=0.5, label='Communal Score', color='blue')\n",
    "df['agentic_score'].plot(kind='hist', alpha=0.5, label='Agentic Score', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.title('Distribution of Communal and Agentic Scores in Job Descriptions')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['communal_freq'].plot(kind='hist', alpha=0.5, label='Communal Frequency', color='blue')\n",
    "df['agentic_freq'].plot(kind='hist', alpha=0.5, label='Agentic Frequency', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Frequency')\n",
    "plt.title('Distribution of Communal and Agentic Frequencies in Job Descriptions')\n",
    "plt.show()\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Statistical Summary\n",
    "Calculate basic statistics for numerical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "basic_stats = df.describe()\n",
    "print(basic_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate communal and agentic scores\n",
    "df['communal_score'] = df['cleaned_description'].apply(lambda x: count_words(x, communal_words))\n",
    "df['agentic_score'] = df['cleaned_description'].apply(lambda x: count_words(x, agentic_words))\n",
    "\n",
    "# Calculate frequency of communal and agentic words\n",
    "df['communal_freq'] = df['communal_score'] / df['cleaned_description'].apply(len)\n",
    "df['agentic_freq'] = df['agentic_score'] / df['cleaned_description'].apply(len)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['communal_score'].plot(kind='hist', alpha=0.5, label='Communal Score', color='blue')\n",
    "df['agentic_score'].plot(kind='hist', alpha=0.5, label='Agentic Score', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.title('Distribution of Communal and Agentic Scores in Job Descriptions')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['communal_freq'].plot(kind='hist', alpha=0.5, label='Communal Frequency', color='blue')\n",
    "df['agentic_freq'].plot(kind='hist', alpha=0.5, label='Agentic Frequency', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Frequency')\n",
    "plt.title('Distribution of Communal and Agentic Frequencies in Job Descriptions')\n",
    "plt.show()\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Communal and Agentic Scores\n",
    "Visualize the distribution of communal and agentic scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Communal and Agentic Scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['communal_score'].plot(kind='hist', alpha=0.5, label='Communal Score', color='blue')\n",
    "df['agentic_score'].plot(kind='hist', alpha=0.5, label='Agentic Score', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.title('Distribution of Communal and Agentic Scores in Job Descriptions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency Analysis\n",
    "Generate word clouds for communal and agentic words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Frequency Analysis (Word Clouds)\n",
    "communal_words = ' '.join(df[df['communal_score'] > 0]['cleaned_description'])\n",
    "agentic_words = ' '.join(df[df['agentic_score'] > 0]['cleaned_description'])\n",
    "\n",
    "# Generate word clouds\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "wordcloud_comm = WordCloud(width=800, height=400, background_color='white').generate(communal_words)\n",
    "plt.imshow(wordcloud_comm, interpolation='bilinear')\n",
    "plt.title('Communal Words')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "wordcloud_agentic = WordCloud(width=800, height=400, background_color='white').generate(agentic_words)\n",
    "plt.imshow(wordcloud_agentic, interpolation='bilinear')\n",
    "plt.title('Agentic Words')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Frequency Analysis (Word Clouds)\n",
    "communal_words = ' '.join(df[df['communal_score'] > 0]['cleaned_description'])\n",
    "\n",
    "# Generate word clouds\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "wordcloud_comm = WordCloud(width=800, height=400, background_color='white').generate(communal_words)\n",
    "plt.imshow(wordcloud_comm, interpolation='bilinear')\n",
    "plt.title('Communal Words')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Frequency Analysis (Word Clouds)\n",
    "agentic_words = ' '.join(df[df['agentic_score'] > 0]['cleaned_description'])\n",
    "\n",
    "# Generate word clouds\n",
    "plt.subplot(1, 2, 2)\n",
    "wordcloud_agentic = WordCloud(width=800, height=400, background_color='white').generate(agentic_words)\n",
    "plt.imshow(wordcloud_agentic, interpolation='bilinear')\n",
    "plt.title('Agentic Words')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "Analyze and visualize sentiment distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "df['sentiment'] = df['cleaned_description'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['sentiment'].plot(kind='hist', bins=20, alpha=0.7, color='purple')\n",
    "plt.xlabel('Sentiment Polarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Sentiment Polarity in Job Descriptions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis calculates the sentiment polarity of each job description text. Sentiment polarity typically ranges from -1 to +1:\n",
    "Negative Sentiment: Close to -1 indicates negative sentiment (e.g., unhappy, critical).\n",
    "Neutral Sentiment: Around 0 indicates neutral sentiment (e.g., factual, objective).\n",
    "Positive Sentiment: Close to +1 indicates positive sentiment (e.g., happy, satisfied).\n",
    "\n",
    "The visualization often takes the form of a histogram.\n",
    "X-axis: Represents the sentiment polarity values ranging from -1 (negative) to +1 (positive).\n",
    "Y-axis: Represents the frequency or count of job descriptions falling into each sentiment polarity range.\n",
    "A bell-shaped curve centered around 0 indicates a balanced mix of positive and negative sentiments.\n",
    "Skewed distributions towards the negative or positive ends suggest prevalent sentiment trends in the dataset.\n",
    "\n",
    "Sentiment Trends: Analyzing the histogram helps in understanding whether the majority of job descriptions are positively, neutrally, or negatively perceived.\n",
    "\n",
    "Variability: Variability in sentiment scores indicates diversity in the emotional tone of job descriptions, which may influence candidate perceptions and application decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readability Metrics Analysis\n",
    "Visualize readability metrics distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readability Metrics\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['flesch_reading_ease'].plot(kind='hist', bins=20, alpha=0.7, color='orange', label='Flesch Reading Ease')\n",
    "df['flesch_kincaid_grade'].plot(kind='hist', bins=20, alpha=0.5, color='blue', label='Flesch Kincaid Grade')\n",
    "plt.legend()\n",
    "plt.xlabel('Readability Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Readability Scores in Job Descriptions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Flesch Reading Ease and Flesch-Kincaid Grade Level are readability metrics commonly used to assess the complexity and difficulty of written text, including job descriptions. Here's what each metric indicates:\n",
    "\n",
    "Flesch Reading Ease\n",
    "The Flesch Reading Ease score is a measure of how easy a piece of text is to read. It is calculated based on the average number of syllables per word and the average number of words per sentence in the text. The formula for calculating the Flesch Reading Ease score is:\n",
    "\n",
    "206.835\n",
    "−\n",
    "1.015\n",
    "×\n",
    "(\n",
    "average words per sentence\n",
    ")\n",
    "−\n",
    "84.6\n",
    "×\n",
    "(\n",
    "average syllables per word\n",
    ")\n",
    "206.835−1.015×(average words per sentence)−84.6×(average syllables per word)\n",
    "\n",
    "The score typically ranges from 0 to 100, where higher scores indicate easier readability:\n",
    "\n",
    "90-100: Very easy to read. Easily understandable by an average 11-year-old student.\n",
    "80-89: Easy to read. Understandable by 6th-grade students.\n",
    "70-79: Fairly easy to read. Understandable by 7th-8th grade students.\n",
    "60-69: Standard readability. Understandable by 9th-10th grade students.\n",
    "50-59: Fairly difficult to read. Understandable by high school graduates.\n",
    "30-49: Difficult to read. Understandable by college graduates.\n",
    "0-29: Very difficult to read. Best understood by university graduates.\n",
    "Flesch-Kincaid Grade Level\n",
    "The Flesch-Kincaid Grade Level is another readability test that assesses the approximate grade level required to understand a piece of text. It calculates the grade level based on the average number of words per sentence and the average number of syllables per word. The formula is:\n",
    "\n",
    "0.39\n",
    "×\n",
    "(\n",
    "average words per sentence\n",
    ")\n",
    "+\n",
    "11.8\n",
    "×\n",
    "(\n",
    "average syllables per word\n",
    ")\n",
    "−\n",
    "15.59\n",
    "0.39×(average words per sentence)+11.8×(average syllables per word)−15.59\n",
    "\n",
    "The result is a score that corresponds to a U.S. grade level. For example, a score of 8.0 indicates that the text is readable by an average eighth grader.\n",
    "\n",
    "Interpretation\n",
    "Lower Scores: Indicate more complex and difficult-to-read text.\n",
    "Higher Scores: Indicate easier and more accessible text.\n",
    "In the context of job descriptions, these metrics can help gauge how understandable and accessible the language is, which is crucial for attracting a diverse pool of applicants and ensuring clarity in communication."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b69611a5e908fff52739484b03ed04ac3b781fc2c02522f7e97d7b5506d2f83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
