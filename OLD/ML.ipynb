{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Job Title', 'Salary Estimate', 'Job Description',\n",
      "       'Rating', 'Company Name', 'Location', 'Headquarters', 'Size', 'Founded',\n",
      "       'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors',\n",
      "       'hourly', 'employer_provided', 'min_salary', 'max_salary', 'avg_salary',\n",
      "       'company_txt', 'job_state', 'same_state', 'age', 'python_yn', 'R_yn',\n",
      "       'spark', 'aws', 'excel', 'job_simp', 'seniority', 'desc_len',\n",
      "       'num_comp', 'headquarters_state', 'Lemmatized_Description',\n",
      "       'Agentic_Words', 'Communal_Words', 'Agentic_Count', 'Communal_Count',\n",
      "       'Gendered_Ratio', 'job_state_encoded', 'headquarters_state_encoded',\n",
      "       'Type of ownership_encoded', 'Industry_encoded', 'Sector_encoded',\n",
      "       'job_simp_encoded', 'seniority_encoded', 'num_comp_encoded', 'Ratio',\n",
      "       'Gender_Bias'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned dataset\n",
    "df = pd.read_csv('gendered_data.csv')\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for classifying gender bias based on scores or frequencies\n",
    "# For example, you can use mean, median, or any other criteria based on your analysis\n",
    "# Here, we'll assume a simple threshold for demonstration purposes\n",
    "\n",
    "# Calculate mean or median of communal and agentic scores/frequencies\n",
    "communal_mean = df['Communal_Count'].mean()\n",
    "agentic_mean = df['Agentic_Count'].mean()\n",
    "\n",
    "# Define a function to classify gender bias\n",
    "def classify_gender_bias(row):\n",
    "    # You can adjust this condition based on your analysis\n",
    "    if row['Communal_Count'] > communal_mean and row['Agentic_Count'] > agentic_mean:\n",
    "        return 1  # Indicates gender bias present\n",
    "    else:\n",
    "        return 0  # Indicates no gender bias or less bias\n",
    "\n",
    "# Apply the function to create the gender_bias_label column\n",
    "df['gender_bias_label'] = df.apply(classify_gender_bias, axis=1)\n",
    "\n",
    "# If using frequencies instead of scores, adjust the condition accordingly:\n",
    "# def classify_gender_bias(row):\n",
    "#     if row['communal_freq'] > communal_mean and row['agentic_freq'] > agentic_mean:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# Optionally, you can use different thresholds or more complex criteria based on your analysis.\n",
    "# This simple example assumes that higher than mean scores indicate bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['seniority_level', 'sentiment', 'flesch_reading_ease'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Assuming X and y are defined as per your dataset structure\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39mCommunal_Count\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAgentic_Count\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mseniority_level\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mflesch_reading_ease\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mgender_bias_label\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39m# Define preprocessing steps including handling categorical variables\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_indexer_strict(key, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['seniority_level', 'sentiment', 'flesch_reading_ease'] not in index\""
     ]
    }
   ],
   "source": [
    "# Assuming X and y are defined as per your dataset structure\n",
    "X = df[['Communal_Count', 'Agentic_Count', 'seniority_level', 'sentiment', 'flesch_reading_ease']]\n",
    "y = df['gender_bias_label']\n",
    "\n",
    "# Define preprocessing steps including handling categorical variables\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(), ['seniority_level'])  # Encode 'seniority_level'\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to resample the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define pipeline with preprocessing and classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', column_transformer),\n",
    "    ('classifier', LogisticRegression())  # Example classifier, replace with your choice\n",
    "])\n",
    "\n",
    "# Define parameters for grid search\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate best model on test data\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming X and y are defined as per your dataset structure\n",
    "X = df[['communal_freq', 'agentic_freq', 'seniority_level', 'sentiment', 'flesch_reading_ease']]\n",
    "y = df['gender_bias_label']\n",
    "\n",
    "# Define preprocessing steps including handling categorical variables\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(), ['seniority_level'])  # Encode 'seniority_level'\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define pipeline with preprocessing and classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', column_transformer),\n",
    "    ('smote', SMOTE(random_state=42)),  # Apply SMOTE after preprocessing\n",
    "    ('classifier', LogisticRegression())  # Example classifier, replace with your choice\n",
    "])\n",
    "\n",
    "# Define parameters for grid search\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate best model on test data\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = df[['communal_score', 'agentic_score', 'seniority_level', 'sentiment', 'flesch_reading_ease']]\n",
    "y = df['gender_bias_label']  # Assuming you have a label for gender bias (binary classification)\n",
    "\n",
    "# Handle categorical variables (seniority_level)\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(), ['seniority_level'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define pipeline for preprocessing and model training\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', column_transformer),\n",
    "    ('classifier', LogisticRegression())  # Example classifier, replace with your choice\n",
    "])\n",
    "\n",
    "# Define parameters for grid search (example)\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "\n",
    "# Assuming X_train and y_train are your training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define your pipeline with Logistic Regression (example)\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define parameter grid for GridSearchCV (example)\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1.0, 10.0],\n",
    "    'classifier__solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# Perform grid search with resampled data\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate best model on test data\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform grid search to find best parameters\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate best model on test data\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the best model for deployment\n",
    "import joblib\n",
    "joblib.dump(best_model, 'gender_bias_detection_model.pkl')\n",
    "\n",
    "# Example of how to load the model later\n",
    "# loaded_model = joblib.load('gender_bias_detection_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b69611a5e908fff52739484b03ed04ac3b781fc2c02522f7e97d7b5506d2f83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
