{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame and target for illustration (replace with your actual data)\n",
    "X_train = pd.read_csv('model_data.csv')\n",
    "y_train = X_train.pop('Gender_Bias')  # Assuming the target column is separated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    'Rating', 'Founded', 'hourly', 'employer_provided', 'min_salary', \n",
    "    'max_salary', 'avg_salary', 'same_state', 'age', 'python_yn', \n",
    "    'R_yn', 'spark', 'aws', 'excel', 'desc_len', 'num_comp', \n",
    "    'Agentic_Count', 'Communal_Count', 'Gendered_Ratio', \n",
    "    'job_state_encoded', 'headquarters_state_encoded', 'Type of ownership_encoded',\n",
    "    'Industry_encoded', 'Sector_encoded', 'job_simp_encoded', \n",
    "    'seniority_encoded', 'num_comp_encoded'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'job_state_encoded', 'headquarters_state_encoded', 'Type of ownership_encoded', 'Industry_encoded',\n",
    "    'Sector_encoded', 'job_simp_encoded', 'seniority_encoded', 'num_comp_encoded'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imPipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Define important features\n",
    "important_features = [\n",
    "    'desc_len', 'max_salary', 'avg_salary', 'Gendered_Ratio', 'min_salary',\n",
    "    'Communal_Count', 'Agentic_Count', 'Founded', 'age', 'Rating',\n",
    "    'job_state_encoded', 'Industry_encoded', 'headquarters_state_encoded',\n",
    "    'Sector_encoded', 'job_simp_encoded', 'Type of ownership_encoded'\n",
    "]\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numerical_features = [\n",
    "    'Rating', 'Founded', 'hourly', 'employer_provided', 'min_salary', \n",
    "    'max_salary', 'avg_salary', 'same_state', 'age', 'python_yn', \n",
    "    'R_yn', 'spark', 'aws', 'excel', 'desc_len', 'num_comp', \n",
    "    'Agentic_Count', 'Communal_Count', 'Gendered_Ratio', \n",
    "    'job_state_encoded', 'headquarters_state_encoded', 'Type of ownership_encoded',\n",
    "    'Industry_encoded', 'Sector_encoded', 'job_simp_encoded', \n",
    "    'seniority_encoded', 'num_comp_encoded'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'job_state_encoded', 'headquarters_state_encoded', 'Type of ownership_encoded',\n",
    "    'Industry_encoded', 'Sector_encoded', 'job_simp_encoded', 'seniority_encoded', \n",
    "    'num_comp_encoded'\n",
    "]\n",
    "\n",
    "# Define preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Define pipeline with SMOTE\n",
    "pipeline_smote = imPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', smote),\n",
    "    ('classifier', RandomForestClassifier(max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100))\n",
    "])\n",
    "\n",
    "# Fit pipeline with SMOTE\n",
    "pipeline_smote.fit(X_train[important_features], y_train)\n",
    "\n",
    "# Evaluate the pipeline\n",
    "y_pred = pipeline_smote.predict(X_test[important_features])\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix:\n",
    "\n",
    "[[32 36]\n",
    " [40 41]]\n",
    "\n",
    "The matrix is a 2x2 array showing the counts of true positives, true negatives, false positives, and false negatives:\n",
    "- True Positives (TP): 41 (correctly predicted positive samples)\n",
    "- True Negatives (TN): 32 (correctly predicted negative samples)\n",
    "- False Positives (FP): 36 (incorrectly predicted positive samples)\n",
    "- False Negatives (FN): 40 (incorrectly predicted negative samples)\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "Precision: The ratio of correctly predicted positive observations to the total predicted positives. For class 0, it's 0.44; for class 1, it's 0.53.\n",
    "\n",
    "Recall: The ratio of correctly predicted positive observations to all observations in the actual class. For class 0, it's 0.47; for class 1, it's 0.51.\n",
    "\n",
    "F1-Score: The weighted average of Precision and Recall. It considers both false positives and false negatives. For class 0, it's 0.46; for class 1, it's 0.52.\n",
    "\n",
    "Support: The number of actual occurrences of the class in the dataset.\n",
    "\n",
    "Overall Accuracy:\n",
    "\n",
    "The model's accuracy is 0.49, which means it correctly predicts the class 49% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "desc_len: 0.0558\n",
      "max_salary: 0.0489\n",
      "avg_salary: 0.0475\n",
      "Gendered_Ratio: 0.0467\n",
      "min_salary: 0.0467\n",
      "Communal_Count: 0.0451\n",
      "Agentic_Count: 0.0423\n",
      "Founded: 0.0413\n",
      "age: 0.0390\n",
      "Rating: 0.0367\n",
      "job_state_encoded: 0.0292\n",
      "Industry_encoded: 0.0268\n",
      "headquarters_state_encoded: 0.0256\n",
      "Sector_encoded: 0.0248\n",
      "job_simp_encoded: 0.0202\n",
      "Type of ownership_encoded: 0.0134\n",
      "excel: 0.0113\n",
      "same_state: 0.0105\n",
      "python_yn: 0.0102\n",
      "job_simp_encoded_1: 0.0096\n",
      "aws: 0.0095\n",
      "num_comp_encoded: 0.0093\n",
      "job_simp_encoded_2: 0.0093\n",
      "num_comp: 0.0092\n",
      "seniority_encoded_1: 0.0091\n",
      "Type of ownership_encoded_2: 0.0089\n",
      "seniority_encoded: 0.0086\n",
      "job_state_encoded_2: 0.0085\n",
      "Sector_encoded_13: 0.0085\n",
      "num_comp_encoded_0: 0.0083\n",
      "Type of ownership_encoded_3: 0.0081\n",
      "spark: 0.0080\n",
      "seniority_encoded_2: 0.0077\n",
      "Sector_encoded_6: 0.0066\n",
      "job_simp_encoded_6: 0.0059\n",
      "headquarters_state_encoded_23: 0.0058\n",
      "job_state_encoded_16: 0.0055\n",
      "headquarters_state_encoded_6: 0.0054\n",
      "num_comp_encoded_3: 0.0054\n",
      "Sector_encoded_10: 0.0048\n",
      "job_simp_encoded_0: 0.0046\n",
      "headquarters_state_encoded_31: 0.0042\n",
      "job_state_encoded_25: 0.0041\n",
      "Sector_encoded_15: 0.0041\n",
      "Industry_encoded_8: 0.0040\n",
      "Industry_encoded_33: 0.0040\n",
      "headquarters_state_encoded_43: 0.0039\n",
      "Industry_encoded_11: 0.0037\n",
      "headquarters_state_encoded_44: 0.0036\n",
      "Industry_encoded_19: 0.0035\n",
      "Sector_encoded_5: 0.0035\n",
      "Industry_encoded_30: 0.0034\n",
      "job_state_encoded_17: 0.0034\n",
      "Sector_encoded_14: 0.0032\n",
      "job_state_encoded_21: 0.0031\n",
      "job_state_encoded_5: 0.0031\n",
      "Type of ownership_encoded_9: 0.0030\n",
      "num_comp_encoded_2: 0.0030\n",
      "job_state_encoded_32: 0.0030\n",
      "job_state_encoded_23: 0.0030\n",
      "headquarters_state_encoded_30: 0.0029\n",
      "job_state_encoded_34: 0.0028\n",
      "job_simp_encoded_4: 0.0028\n",
      "Type of ownership_encoded_6: 0.0028\n",
      "headquarters_state_encoded_18: 0.0027\n",
      "headquarters_state_encoded_28: 0.0026\n",
      "Industry_encoded_2: 0.0026\n",
      "job_state_encoded_11: 0.0026\n",
      "job_state_encoded_35: 0.0026\n",
      "Industry_encoded_3: 0.0026\n",
      "Industry_encoded_34: 0.0025\n",
      "Industry_encoded_13: 0.0025\n",
      "headquarters_state_encoded_10: 0.0025\n",
      "Industry_encoded_45: 0.0024\n",
      "Sector_encoded_12: 0.0023\n",
      "Industry_encoded_28: 0.0022\n",
      "Sector_encoded_2: 0.0021\n",
      "headquarters_state_encoded_24: 0.0020\n",
      "Industry_encoded_15: 0.0019\n",
      "job_state_encoded_28: 0.0019\n",
      "job_simp_encoded_5: 0.0018\n",
      "Sector_encoded_21: 0.0017\n",
      "Sector_encoded_9: 0.0016\n",
      "headquarters_state_encoded_7: 0.0016\n",
      "num_comp_encoded_1: 0.0016\n",
      "job_simp_encoded_3: 0.0016\n",
      "job_state_encoded_33: 0.0016\n",
      "hourly: 0.0016\n",
      "Type of ownership_encoded_1: 0.0015\n",
      "Industry_encoded_37: 0.0015\n",
      "headquarters_state_encoded_40: 0.0015\n",
      "headquarters_state_encoded_41: 0.0015\n",
      "job_state_encoded_31: 0.0014\n",
      "job_state_encoded_20: 0.0014\n",
      "headquarters_state_encoded_12: 0.0014\n",
      "headquarters_state_encoded_16: 0.0014\n",
      "headquarters_state_encoded_34: 0.0014\n",
      "Sector_encoded_4: 0.0013\n",
      "Sector_encoded_11: 0.0013\n",
      "employer_provided: 0.0013\n",
      "job_state_encoded_26: 0.0013\n",
      "Industry_encoded_25: 0.0013\n",
      "Sector_encoded_18: 0.0013\n",
      "headquarters_state_encoded_39: 0.0013\n",
      "Industry_encoded_32: 0.0012\n",
      "job_state_encoded_7: 0.0012\n",
      "job_state_encoded_12: 0.0012\n",
      "Industry_encoded_10: 0.0012\n",
      "headquarters_state_encoded_42: 0.0012\n",
      "job_state_encoded_3: 0.0012\n",
      "Industry_encoded_16: 0.0012\n",
      "Sector_encoded_23: 0.0011\n",
      "job_state_encoded_36: 0.0011\n",
      "headquarters_state_encoded_29: 0.0011\n",
      "Industry_encoded_6: 0.0011\n",
      "job_state_encoded_4: 0.0011\n",
      "Industry_encoded_49: 0.0010\n",
      "headquarters_state_encoded_46: 0.0010\n",
      "Industry_encoded_43: 0.0010\n",
      "headquarters_state_encoded_19: 0.0009\n",
      "headquarters_state_encoded_45: 0.0009\n",
      "Type of ownership_encoded_5: 0.0009\n",
      "Sector_encoded_20: 0.0009\n",
      "Industry_encoded_56: 0.0009\n",
      "Industry_encoded_26: 0.0009\n",
      "Industry_encoded_18: 0.0008\n",
      "Industry_encoded_21: 0.0008\n",
      "headquarters_state_encoded_27: 0.0008\n",
      "headquarters_state_encoded_21: 0.0008\n",
      "Industry_encoded_0: 0.0008\n",
      "headquarters_state_encoded_32: 0.0008\n",
      "job_state_encoded_0: 0.0008\n",
      "job_state_encoded_1: 0.0008\n",
      "job_state_encoded_22: 0.0008\n",
      "Industry_encoded_59: 0.0007\n",
      "headquarters_state_encoded_14: 0.0007\n",
      "Industry_encoded_22: 0.0007\n",
      "Industry_encoded_35: 0.0007\n",
      "Type of ownership_encoded_4: 0.0007\n",
      "Type of ownership_encoded_7: 0.0007\n",
      "Industry_encoded_24: 0.0007\n",
      "Industry_encoded_23: 0.0007\n",
      "job_state_encoded_15: 0.0006\n",
      "headquarters_state_encoded_13: 0.0006\n",
      "job_state_encoded_9: 0.0006\n",
      "job_state_encoded_8: 0.0006\n",
      "Industry_encoded_36: 0.0006\n",
      "Industry_encoded_46: 0.0006\n",
      "job_state_encoded_27: 0.0006\n",
      "job_state_encoded_29: 0.0005\n",
      "Industry_encoded_9: 0.0005\n",
      "seniority_encoded_0: 0.0005\n",
      "job_state_encoded_13: 0.0005\n",
      "Industry_encoded_55: 0.0005\n",
      "job_state_encoded_18: 0.0005\n",
      "Sector_encoded_19: 0.0005\n",
      "Industry_encoded_38: 0.0005\n",
      "headquarters_state_encoded_25: 0.0005\n",
      "Industry_encoded_31: 0.0005\n",
      "headquarters_state_encoded_15: 0.0005\n",
      "R_yn: 0.0005\n",
      "Industry_encoded_4: 0.0005\n",
      "Sector_encoded_24: 0.0004\n",
      "headquarters_state_encoded_20: 0.0004\n",
      "headquarters_state_encoded_17: 0.0004\n",
      "Sector_encoded_16: 0.0004\n",
      "Industry_encoded_17: 0.0004\n",
      "Sector_encoded_17: 0.0004\n",
      "Sector_encoded_0: 0.0004\n",
      "Industry_encoded_14: 0.0004\n",
      "Industry_encoded_58: 0.0004\n",
      "job_state_encoded_19: 0.0004\n",
      "headquarters_state_encoded_33: 0.0004\n",
      "Sector_encoded_22: 0.0004\n",
      "job_state_encoded_24: 0.0004\n",
      "Industry_encoded_47: 0.0003\n",
      "headquarters_state_encoded_1: 0.0003\n",
      "Industry_encoded_29: 0.0003\n",
      "job_state_encoded_14: 0.0003\n",
      "Type of ownership_encoded_10: 0.0003\n",
      "Industry_encoded_7: 0.0003\n",
      "headquarters_state_encoded_0: 0.0003\n",
      "job_state_encoded_10: 0.0003\n",
      "Industry_encoded_51: 0.0003\n",
      "Type of ownership_encoded_8: 0.0003\n",
      "Industry_encoded_50: 0.0003\n",
      "headquarters_state_encoded_5: 0.0003\n",
      "Industry_encoded_48: 0.0003\n",
      "job_state_encoded_30: 0.0003\n",
      "headquarters_state_encoded_26: 0.0003\n",
      "headquarters_state_encoded_3: 0.0003\n",
      "Sector_encoded_8: 0.0003\n",
      "headquarters_state_encoded_4: 0.0003\n",
      "job_state_encoded_6: 0.0002\n",
      "Industry_encoded_54: 0.0002\n",
      "headquarters_state_encoded_2: 0.0002\n",
      "Industry_encoded_44: 0.0002\n",
      "Industry_encoded_53: 0.0002\n",
      "Industry_encoded_12: 0.0002\n",
      "Industry_encoded_39: 0.0002\n",
      "headquarters_state_encoded_37: 0.0002\n",
      "headquarters_state_encoded_35: 0.0002\n",
      "Industry_encoded_1: 0.0002\n",
      "Industry_encoded_40: 0.0002\n",
      "headquarters_state_encoded_11: 0.0002\n",
      "headquarters_state_encoded_38: 0.0002\n",
      "Industry_encoded_27: 0.0001\n",
      "Industry_encoded_42: 0.0001\n",
      "Sector_encoded_1: 0.0001\n",
      "Type of ownership_encoded_0: 0.0001\n",
      "Industry_encoded_20: 0.0001\n",
      "Industry_encoded_52: 0.0001\n",
      "headquarters_state_encoded_8: 0.0001\n",
      "Sector_encoded_3: 0.0001\n",
      "Sector_encoded_7: 0.0001\n",
      "Industry_encoded_5: 0.0001\n",
      "headquarters_state_encoded_22: 0.0001\n",
      "headquarters_state_encoded_36: 0.0001\n",
      "headquarters_state_encoded_9: 0.0001\n",
      "num_comp_encoded_4: 0.0000\n",
      "Industry_encoded_41: 0.0000\n",
      "Industry_encoded_57: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the entire dataset\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importances\n",
    "importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Combine feature names with importances\n",
    "feature_names = (pipeline.named_steps['preprocessor']\n",
    "                    .transformers_[0][1].get_feature_names_out().tolist() + \n",
    "                    pipeline.named_steps['preprocessor']\n",
    "                    .transformers_[1][1].get_feature_names_out().tolist())\n",
    "feature_importance_dict = dict(zip(feature_names, importances))\n",
    "\n",
    "# Sort and display feature importances\n",
    "sorted_importances = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in sorted_importances:\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n",
      "Best score:  0.5463324312775959\n",
      "Confusion Matrix:\n",
      "[[35 33]\n",
      " [43 38]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.51      0.48        68\n",
      "           1       0.54      0.47      0.50        81\n",
      "\n",
      "    accuracy                           0.49       149\n",
      "   macro avg       0.49      0.49      0.49       149\n",
      "weighted avg       0.50      0.49      0.49       149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for RandomForestClassifier\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict with the best model\n",
    "y_pred_best = grid_search.predict(X_valid_split)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_valid_split, y_pred_best))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_valid_split, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters Found\n",
    "max_depth: 10\n",
    "min_samples_leaf: 1\n",
    "min_samples_split: 5\n",
    "n_estimators: 100\n",
    "\n",
    "Best Score\n",
    "Accuracy: 0.5463 (approximately 54.63%)\n",
    "\n",
    "Updated Confusion Matrix\n",
    "\n",
    "[[35 33]\n",
    " [43 38]]\n",
    "\n",
    "    True Positives (TP): 38\n",
    "    True Negatives (TN): 35\n",
    "    False Positives (FP): 33\n",
    "    False Negatives (FN): 43\n",
    "\n",
    "Updated Classification Report\n",
    "\n",
    "Precision:\n",
    "\n",
    "    Class 0: 0.45\n",
    "    Class 1: 0.54\n",
    "\n",
    "Recall:\n",
    "\n",
    "    Class 0: 0.51\n",
    "    Class 1: 0.47\n",
    "\n",
    "F1-Score:\n",
    "\n",
    "    Class 0: 0.48\n",
    "    Class 1: 0.50\n",
    "\n",
    "Overall Accuracy: 0.49\n",
    "\n",
    "Observations:\n",
    "\n",
    "Precision for Class 1 improved slightly, but recall decreased.\n",
    "\n",
    "F1-scores are relatively close for both classes, indicating a balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing Data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = [\n",
    "    'desc_len',\n",
    "    'max_salary',\n",
    "    'avg_salary',\n",
    "    'Gendered_Ratio',\n",
    "    'min_salary',\n",
    "    'Communal_Count',\n",
    "    'Agentic_Count',\n",
    "    'Founded',\n",
    "    'age',\n",
    "    'Rating',\n",
    "    'job_state_encoded',\n",
    "    'Industry_encoded',\n",
    "    'headquarters_state_encoded',\n",
    "    'Sector_encoded',\n",
    "    'job_simp_encoded',\n",
    "    'Type of ownership_encoded',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important_features = [\n",
    "#    'Rating', 'Founded', 'min_salary', 'max_salary', 'avg_salary', 'age', \n",
    "#    'desc_len', 'Agentic_Count', 'Communal_Count', 'Gendered_Ratio', 'Ratio'\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hourly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/sklearn/utils/__init__.py:505\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns:\n\u001b[0;32m--> 505\u001b[0m     col_idx \u001b[39m=\u001b[39m all_columns\u001b[39m.\u001b[39mget_loc(col)\n\u001b[1;32m    506\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(col_idx, numbers\u001b[39m.\u001b[39mIntegral):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hourly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 28\u001b[0m\n\u001b[1;32m     20\u001b[0m pipeline_smote \u001b[39m=\u001b[39m imPipeline(steps\u001b[39m=\u001b[39m[\n\u001b[1;32m     21\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m, preprocessor),\n\u001b[1;32m     22\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39msmote\u001b[39m\u001b[39m'\u001b[39m, smote),\n\u001b[1;32m     23\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m, RandomForestClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, min_samples_leaf\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, min_samples_split\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m))\n\u001b[1;32m     24\u001b[0m ])\n\u001b[1;32m     27\u001b[0m \u001b[39m# Fit pipeline with SMOTE\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m pipeline_smote\u001b[39m.\u001b[39mfit(X_train[important_features], y_train)\n\u001b[1;32m     30\u001b[0m \u001b[39m# Evaluate the pipeline\u001b[39;00m\n\u001b[1;32m     31\u001b[0m y_pred \u001b[39m=\u001b[39m pipeline_smote\u001b[39m.\u001b[39mpredict(X_test[important_features])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/imblearn/pipeline.py:329\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \n\u001b[1;32m    287\u001b[0m \u001b[39mFit all the transforms/samplers one after the other and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39m    This estimator.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    328\u001b[0m routed_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_method_params(method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m, props\u001b[39m=\u001b[39mparams)\n\u001b[0;32m--> 329\u001b[0m Xt, yt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, routed_params)\n\u001b[1;32m    330\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    331\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/imblearn/pipeline.py:255\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(cloned_transformer, \u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[1;32m    253\u001b[0m     cloned_transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m ):\n\u001b[0;32m--> 255\u001b[0m     X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    256\u001b[0m         cloned_transformer,\n\u001b[1;32m    257\u001b[0m         X,\n\u001b[1;32m    258\u001b[0m         y,\n\u001b[1;32m    259\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    260\u001b[0m         message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    261\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[1;32m    262\u001b[0m         params\u001b[39m=\u001b[39mrouted_params[name],\n\u001b[1;32m    263\u001b[0m     )\n\u001b[1;32m    264\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(cloned_transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_resample\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    265\u001b[0m     X, y, fitted_transformer \u001b[39m=\u001b[39m fit_resample_one_cached(\n\u001b[1;32m    266\u001b[0m         cloned_transformer,\n\u001b[1;32m    267\u001b[0m         X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m         params\u001b[39m=\u001b[39mrouted_params[name],\n\u001b[1;32m    272\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/joblib/memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 312\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/imblearn/pipeline.py:1104\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1103\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1104\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m, {}))\n\u001b[1;32m   1105\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m, {}))\u001b[39m.\u001b[39mtransform(\n\u001b[1;32m   1107\u001b[0m             X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m, {})\n\u001b[1;32m   1108\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    296\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:906\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_transformers()\n\u001b[1;32m    904\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 906\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    907\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    909\u001b[0m \u001b[39mif\u001b[39;00m _routing_enabled():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:496\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    494\u001b[0m         columns \u001b[39m=\u001b[39m columns(X)\n\u001b[1;32m    495\u001b[0m     all_columns\u001b[39m.\u001b[39mappend(columns)\n\u001b[0;32m--> 496\u001b[0m     transformer_to_input_indices[name] \u001b[39m=\u001b[39m _get_column_indices(X, columns)\n\u001b[1;32m    498\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_columns \u001b[39m=\u001b[39m all_columns\n\u001b[1;32m    499\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer_to_input_indices \u001b[39m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds-venv/lib/python3.11/site-packages/sklearn/utils/__init__.py:513\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    510\u001b[0m         column_indices\u001b[39m.\u001b[39mappend(col_idx)\n\u001b[1;32m    512\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 513\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mA given column is not a column of the dataframe\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39mreturn\u001b[39;00m column_indices\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imPipeline\n",
    "\n",
    "\n",
    "# Define preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)  # Ensure categorical_features are updated correctly\n",
    "    ])\n",
    "\n",
    "# Define SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Define pipeline with SMOTE\n",
    "pipeline_smote = imPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', smote),\n",
    "    ('classifier', RandomForestClassifier(max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100))\n",
    "])\n",
    "\n",
    "\n",
    "# Fit pipeline with SMOTE\n",
    "pipeline_smote.fit(X_train[important_features], y_train)\n",
    "\n",
    "# Evaluate the pipeline\n",
    "y_pred = pipeline_smote.predict(X_test[important_features])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b69611a5e908fff52739484b03ed04ac3b781fc2c02522f7e97d7b5506d2f83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
