{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "WebDriver.__init__() got an unexpected keyword argument 'service'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m service \u001b[39m=\u001b[39m Service(chromedriver_path)\n\u001b[1;32m     20\u001b[0m \u001b[39m# Initialize Chrome WebDriver\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39mChrome(service\u001b[39m=\u001b[39mservice, options\u001b[39m=\u001b[39mchrome_options)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Initialize DataFrame\u001b[39;00m\n\u001b[1;32m     24\u001b[0m job_dataset \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mJob Title\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCompany\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLocation\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDescription\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: WebDriver.__init__() got an unexpected keyword argument 'service'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-minimized\")\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Set up the Chrome driver\n",
    "chromedriver_path = '/opt/homebrew/bin/chromedriver'  # Modify this path\n",
    "service = Service(chromedriver_path)\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Initialize DataFrame\n",
    "job_dataset = pd.DataFrame(columns=[\"Job Title\", \"Company\", \"Location\", \"Description\"])\n",
    "\n",
    "url = 'https://example.com'  # Replace with your URL\n",
    "\n",
    "try:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "    # Scroll to the bottom of the page to load all job listings\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Parse the page source using BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    job_cards = soup.find_all('div', class_='job-search-card')\n",
    "\n",
    "    for job_card in job_cards:\n",
    "        try:\n",
    "            job_title = job_card.find('h3', class_='job-title').get_text(strip=True)\n",
    "            company = job_card.find('h4', class_='company-name').get_text(strip=True)\n",
    "            location = job_card.find('span', class_='job-location').get_text(strip=True)\n",
    "            job_link = job_card.find('a', class_='job-link')['href']\n",
    "\n",
    "            # Navigate to the job description page\n",
    "            driver.get(job_link)\n",
    "            time.sleep(2)\n",
    "            job_desc_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            job_description = job_desc_soup.find('div', class_='job-description').get_text(strip=True)\n",
    "\n",
    "            # Append data to DataFrame\n",
    "            job_dataset = job_dataset.append({\n",
    "                \"Job Title\": job_title,\n",
    "                \"Company\": company,\n",
    "                \"Location\": location,\n",
    "                \"Description\": job_description\n",
    "            }, ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing job card: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "job_dataset.to_csv(\"data_science_jobs_linkedin.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b69611a5e908fff52739484b03ed04ac3b781fc2c02522f7e97d7b5506d2f83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
